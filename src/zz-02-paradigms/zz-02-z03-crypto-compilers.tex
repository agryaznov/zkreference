%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Cryptographic Compilers (CC)} %and ZKP Systems
\label{paradigms:CC}

This section describes cryptographic compilers (CC) for several of the IT systems described in \refsec{paradigms:IT}.
A CC transforms an IT proof system into a real-world protocol that involves direct interaction between the prover and the verifier. 
The primitives used by a CC are realized by (possibly heuristic) concrete instantiations, such as concrete hash functions or pairing-friendly elliptic curves.
This yields a concrete scheme that can be implemented and used in real-world applications.
The CC may also provide extra desirable properties, such as eliminating interaction, shrinking the size of some of the messages, or even adding a ZK feature to an IT proof system that does not have it.


\label{par:paradigms:background:abstract-vs-concrete}
While the separation between IT proof systems and cryptographic compilers is useful, it is not always precise. 
For some concrete ZKP schemes, there is no neat way to break them into such components, such that when putting them together one obtains the original scheme.%
Thus, the abstractions and classifications presented herein can be considered as useful didactic and taxonomic tools, while much room is left for ingenuity and optimizations for specific ZKP schemes, resulting in differences in concrete in performance and parameters.


The next subsections describe cryptographic compilers for 
zk-PCP (\S\ref{label:CC:zk-PCP})
%%%% Perhaps add historical explanation: PCP's started without ZK, whereas the others were mostly developed within the ZK context, so they wouldn't need the prefix
LPCP (\S\ref{sec:CC-LPCP}),
MPC-in-the-Head (\S\ref{sec:CC-MitH}), 
IOP (\S\ref{sec:CC-IOP}), 
LIOP (\S\ref{sec:CC-LIOP}) and
ILC (\S\ref{sec:CC-ILC}).


\futfig{Illustration of generic crypto compilers, including labels for each main type of IT proof system}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{CC for zk-PCP} 
\label{label:CC:zk-PCP}

\paragraph{\bf Example: 3-coloring}
In the 3-coloring example  $R_{\sf 3COL}$ of \cref{sec:3coloring} above, we assumed the availability of commitments.
To realize this protocol in the real world, we use a cryptographic compiler that relies on cryptographic commitment schemes which are secure under computational assumptions. 
This compiler for  proceeds as follows. Given $(x,w)$, the prover uses the zk-PCP prover to generate a proof $\pi\in\Sigma^m$ and uses the underlying commitment scheme to independently commits to each of the $m$ symbols. 
The verifier uses the zk-PCP verifier to pick a subset $Q$ of the symbols, which it sends as a challenge to the prover. 
The prover opens the symbols $\pi_Q$ after checking that $Q$ is valid (in the sense that it can be generated by an honest verifier). The verifier uses the decision predicate $D$ of the zk-PCP to decide whether to accept. 

\paragraph{Using standard cryptographic assumptions}
While simple and natural, the analysis of the above compiler when using a standard {\em computationally-hiding} commitment scheme \cite{2001:Gol:FOC-vol1} is more subtle than it may seem. 
In particular, efficient simulation requires that the distribution of $Q$ have polynomial-size support. 
This indeed applies to the basic version of the zk-PCP for $R_{\sf 3COL}$, but not to the one with amplified soundness. 
As a result, the compiler yields a (constant-round) zero-knowledge protocol with poor soundness, which can be amplified via sequential repetition. 
An alternative cryptographic compiler, which avoids the polynomial-size support restriction by using a {\em statistically-hiding} commitment scheme (and an even more subtle analysis), is implicit in the work on constant-round zero-knowledge proofs for NP \cite{1996:GK:how-to}. 
Both of the above compilers yield zero-knowledge proof protocols in which the communication complexity is bigger than that of communicating $\pi$; ideally, we would like to make it comparable to only communicating $\pi_Q$. 
As we will see, this can make a big difference. 
\loosen

When instantiated with statistically-binding (and computationally-hiding) commitments, the above compilers yield statistically-sound {\em proofs} rather than computationally-sound arguments. 
In this case, their high communication cost seems inherent, as there is a strong complexity-theoretic evidence \cite{1996:GH:complexity,2002:GVW:IP-laconic-prover} that the prover-to-verifier communication in proof systems for hard NP-relations cannot be much smaller than the witness size.
On the other hand, a different cryptographic compiler \cite{2015:IMSX:on-ZK-PCPs} can use any {\em collision resistant hash function} to obtain a zero-knowledge {\em argument} whose communication complexity is close to just the size of $\pi_Q$, which for some zk-PCPs (that will be discussed later) can be much smaller than the witness size. 
The first compiler of this kind (implicit in the work of Kilian \cite{1992:kilian:note-on-efficient-ZKPs-and-args}) can obtain a similar ZK argument from any PCP, namely zk-PCP without the ZK requirement.
However, in contrast to compilers based on zk-PCP, Kilian's compiler uses the underlying cryptographic primitive in a {\em non-black-box} way \cite{2004:RTV:notions-of-reducibility}, which makes it inefficient in practice.
\loosen


\paragraph{Practical NIZK compiler in the random oracle model}
All of the previous black-box compilers can be analyzed unconditionally if the underlying ``symmetric'' cryptographic primitive is abstracted as a random oracle.  
But one can actually go further and make these interactive public-coin protocols {\em non-interactive}  via the {\em Fiat-Shamir} transform \cite{1987:FS:crypto:How-To-Prove-Yourself}. 
Combining the two steps, we get concretely efficient compilers from any zk-PCP to NIZK in the random oracle model. 
The latter is then heuristically instantiated with a practical hash function based on, say, SHA-256 or AES. 
See the background part for more discussion of this methodology. 
Interestingly, even in the random oracle model, the NIZK does not entirely dominate the interactive protocol on which it is based, since removing interaction can come at a price. 
For instance, consider an interactive protocol with soundness error of $2^{-\sigma}$, where $\sigma$ may be of the order of 40 or 64, as discussed in \refsec{security:efficiency:stat-sec-levels}.
In the NIZK obtained via the Fiat-Shamir transform, the prover can convince the verifier of a false statement with certainty by generating roughly $2^{\sigma}$ random transcripts, until finding one that would lead the verifier to accept. 
This means that the non-interactive variant should rely on a zk-PCP with a considerably smaller soundness error, i.e., with higher $\sigma$ equal to the computational security parameter $\kappa$. 
This would increase the concrete communication and computation costs, though by a small factor (of about $\kappa/\sigma$). 


\paragraph{NIZK from standard cryptographic assumptions}
A recent line of work shows how to instantiate the random oracle in NIZK proofs obtained via the Fiat-Shamir transform under standard cryptographic assumptions.  
These works rely on a special type of correlation-intractable hash functions \cite{1998:CGH:RO-revisited}
together with a special kind of $\Sigma$-protocols \cite{2010:Dam:on-sigma-protocols}, namely 3-message honest-verifier (computational) zero-knowledge proof systems that satisfy some additional properties. 
The latter in turn implicitly rely on a special kind of zk-PCP that can be instantiated with Blum's graph Hamiltonicity protocol \cite{1987:blum:how-to-prove}
but remains to be more systematically explored. 
In contrast to these recent NIZK protocols, the classical approach \cite{1999:FLS:multiple-NIZKPs-under-general-assumptions} for basing NIZK for NP on standard cryptographic assumptions uses a very different kind of information-theoretic proof systems referred to as zero-knowledge proofs in the {\em hidden bits model}. 
Known proofs of this type are more involved and less efficient than their zk-PCP counterparts. 
However, the cryptographic compiler from the hidden bits model to NIZK can rely on the intractability of factoring or, more generally, a suitable kind of {\em trapdoor permutation} \cite{2018:CL:certifying-trapdoor-permutations}. 
An interesting question is whether one can obtain a similar cryptographic compiler from zk-PCP.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{CC for Linear PCP (LPCP)}
\label{sec:CC-LPCP}

Cryptographic compilers for linear PCPs are possible at the cost of an expensive (but reusable) trusted setup, and ``not efficiently falsifiable'' cryptographic assumptions \cite{2003:Naor:on-crypto-assumptions}.
These compilers can yield zk-SNARKs with very short proofs (roughly 1000 bits, or even less in some settings). 
The use of this type of compilers was implicit in some initial schemes \cite{2010:Gro:short-pairing-based-NIZKA,2011:Lip:Progression-Free}, and was later considered explicitly \cite{2013:tcc:snargs-via-LIPs,2013:GGPR:eurocrypt:QSPs-and-succinct-NIZKs-without-PCPs}.
\loosen


Let us start by considering the following natural attempt for compiling an LPCP into a {\em designated verifier} SNARG with a reusable structured reference string (SRS). 
The verifier generates LPCP queries $q_1,\ldots,q_d$ (e.g., $d=3$ in the case of the Hadamard LPCP), and lets the SRS $\sigma$ include a linearly homomorphic encryption of (each entry of) the verifier's queries, denoted by $\sigma = (E(q_1),\ldots,E(q_d))$.  
The verifier keeps the secret key $k_V$ that can be used for decryption. 
Now, given an input $(x,w)$ and $\sigma$, the prover computes an LPCP proof vector $\pi$, and uses the linear homomorphism of $E$ to compute a short SNARG proof $\hat\pi$ consisting of the $d$ ciphertexts $\hat\pi=(E(\langle \pi,q_1\rangle),\ldots,E(\langle \pi,q_d\rangle))$ that it sends as a SNARG proof to the verifier. 
The verifier uses the secret key $k_V$ to decrypt the LPCP answers $a_1=\langle \pi,q_1\rangle,\ldots,a_d=\langle \pi,q_d\rangle$, and applies the LPCP decision predicate to decide whether to accept or reject.

The above attempt to implement LPCP under the hood of homomorphic encryption clearly satisfies the completeness requirement. 
Moreover, it is tempting to believe that, since the encryption hides the queries, the proof $\pi$ is independent of the queries and thus soundness holds as well. 
However, this simplistic soundness argument is flawed for two reasons.
\loosen


First, while a standard linearly homomorphic encryption scheme $E$ supports computing linear functions on encrypted inputs, it provides no guarantee that {\em only} linear functions can be computed. 
In fact, linearly homomorphic encryption can be fully homomorphic \cite{2009:gen:a-FHE-scheme}, in which case soundness completely breaks down.
The solution to this problem is essentially to ``assume it away'' by relying on an encryption scheme $E$ that is conjectured to support {\em only} linear computations on encrypted inputs.
(Alternatively, this can be extended to {\em affine} computations that include a constant term.)
This strong notion of ``linear-only encryption'' \cite{2013:tcc:snargs-via-LIPs} will be discussed in more detail below. 


A second problem is that there is nothing in the above solution that prevents a malicious prover from using a different proof vector $\pi^*_i$ for each encrypted query $E(q_i)$.
This is beyond the capability of a malicious prover in the LPCP model and may thus violate soundness.
A solution to this problem is to have the verifier add to the LPCP an additional query which is a random linear combination of of the original queries, namely $q_{d+1}=\rho_1q_1+\ldots+\rho_d q_d$, and check that the answer to this query satisfies $a_{d+1}=\rho_1a_1+\ldots+\rho_da_d$.
This can be viewed as a simple IT compiler from LPCP to a 1-round {\em linear interactive proof} (LIP) \cite{2013:tcc:snargs-via-LIPs}, a stronger information-theoretic proof system that can be viewed as restricting a standard interactive proof by allowing provers (both honest and malicious) to only compute linear functions of the verifier's messages. 


To sum up: the modified compiler proceeds in two steps.
First, an information-theoretic compiler is applied to convert the LPCP into a LIP.
If the LPCP has proof size $m$ and $d$ queries, the LIP resulting from the simple compiler described above has verifier message consisting of $(d+1)\cdot m$ field elements and prover message consisting of $d+1$ field elements.
Then, linear-only encryption is used to compile the LIP into a designated-verifier SNARG with SRS that consists of $(d+1)\cdot m$ ciphertexts and proof that consists of $d+1$ ciphertexts.
This transformation respects all of the additional features of LPCPs we discussed in the context of the Hadamard LPCP: zero knowledge, fast verification, and reusable soundness.
The latter means that the SRS of the resulting SNARG can be safely reused for multiple proofs.
Finally, when the LPCP is also a ``proof of knowledge'' (which is the case for all natural constructions), and when the linear-only encryption is ``extractable'' (a plausible assumption for concrete instantiations), the resulting (zk)-SNARG is also a proof of knowledge, namely it is a (zk)-SNARK.


There is one remaining issue: the above approach seems inherently restricted to the {\em designated verifier} setting, since only the verifier is able to decrypt the encrypted LIP answers.
While this is good enough for some applications, many applications of SNARGs require public verification.
The solution (initially implicit in the work of Groth \cite{2010:Gro:short-pairing-based-NIZKA}) is to rely once again on a special property of the LPCP, which is respected by the transformation to LIP.
Suppose the LIP verifier's decision predicate is {\em quadratic} in the following sense: 
to decide whether to accept, the verifier tests equalities of the form $p_x({\bf u}, {\bf a})=0$, where $p_x$ is a {\em degree-2} polynomial determined by the input statement $x$, the vector ${\bf u}$ contains state information determined by the LIP query, and the vector ${\bf a}$ contains the LIP answers.
Indeed, this is the case for the Hadamard-based LIP.
Then, public verification can be achieved by using an encryption scheme that allows such quadratic tests to be performed on an encrypted input without knowing the decryption key.
Fortunately, this kind of functionality is supported by pairing-based cryptography.
If the SRS $\sigma$ includes a ``pairing-friendly encryption'' of the LIP query along with the state information ${\bf u}$, which can be implemented using {\em bilinear groups}, the prover on input $(x,w)$ can compute an encryption of the LIP answers $\bf a$, and then {\em everyone} can check that the encrypted $\bf u,a$ satisfy the quadratic relation defined by $x$. 

Several QAP-based constructions (e.g., \cite{2013:GGPR:eurocrypt:QSPs-and-succinct-NIZKs-without-PCPs,2016:Eurocrypt:On-the-Size-of-Pairing-Based-Non-interactive-Arguments}) can be roughly recast as an IT proof system in the \hyperref[paradigms:IT:linear-PCP]{Linear PCP model}, and then be cryptographically compiled (e.g., with \cite{2013:tcc:snargs-via-LIPs}) in a way that results in different proof systems (less succinct by constant factors).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{CC for MPC-in-the-Head}
\label{sec:CC-MitH}

\WANTED[Contribution needed]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{CC for IOP}
\label{sec:CC-IOP}

Using a cryptographic compiler \cite{1988:BGGHKMR:everything-provable} based on one-way functions, the interactive PCPs from \refsec{paradigms:IT:IOP:interactive-PCP} yield statistically-sound ZKP protocols for low-depth (or space-bounded) NP relations in which the communication complexity is comparable to the witness length. 
\loosen

As in the case of classical PCPs, there are cryptographic compilers that use a collision-resistant hash function (respectively, a classical or even quantum random oracle) \cite{2019:CMS:succinct-args-quantum-ROM} to convert fully succinct IOPs into interactive (respectively, non-interactive and transparent) fully succinct arguments for NP.
These compilers naturally extend the ones for classical PCPs. In the interactive variant, the prover uses a Merkle tree to succinctly commit to each proof, following which the verifier generates and sends the random challenge for the next proof.
In the end, the verifier challenges the prover to open the subset of proof symbols that the IOP verifier wants to query, to which the prover responds by revealing the small amount of relevant information on the Merkle trees.
The non-interactive variant is obtained from the interactive one via the Fiat-Shamir heuristic, though the analysis in the random oracle model is considerably more challenging in the interactive case and requires some extra assumptions on the underlying IOP.

On the practical side, transparent SNARKs, such as STARK \cite{2018:BBHR:STARK}, Aurora \cite{2018:CRSVW:aurora} and Fractal \cite{2020:COS:Fractal}, rely on concretely efficient IOPs.
While not quite as succinct as the group-based SNARKs discussed next (with typical proof size in the range of 100--200 kB in the former vs. 1--2 kB in the latter), they have the advantages of being transparent, plausibly post-quantum, and avoiding altogether the use of public-key cryptography.
The latter can be useful for allowing faster provers.
A key technical ingredient in these practical IOPs is the FRI protocol \cite{2018:BBHR:FRI}: an interactive test for proximity of an oracle to a Reed-Solomon code.
A useful feature of the FRI protocol is that it can be realized using a strictly linear number of arithmetic operations.
However, the IOPs that build on top of it still require quasilinear time on the prover side. 


On the theoretical side, the IOP model gives rise to asymptotic efficiency features that are not known to be achievable with classical PCPs.
See \cite{2019:BCGGRS:linear-size,2020:RR:local-proofs} for recent progress on minimizing the {\em proof size} of IOPs.
While proof size is not the main parameter of interest in cryptographic applications of IOPs, as it only serves as a lower bound on the prover's running time, new techniques for constructing IOPs are likely to lead to progress on the concrete efficiency of IOP-based proof systems.
More directly relevant to the concrete efficiency of IOPs are works on improving the analysis of their {\em soundness error}
\cite{2018:BKSS:worst-case,2020:BGKS:DEEP-FRI,2020:BCIKS:proximity-gaps}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{CC for Interactive PCP}
\label{sec:CC-PCP:interactive-PCP}

\WANTED[]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{CC for Linear IOP}
\label{sec:CC-LIOP}

\WANTED[CC for Linear IOP (other than fully linear) / IP-based]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{CC for Fully Linear  IOP}
\label{sec:CC-LIOP:fully-linear}

By having the prover secret-share each proof vector, a fully linear proof system can be compiled \cite{2019:BBCGI:crypto:ZKPs-on-secret-shared-data-via-FLPCP} into a distributed zero-knowledge proof in which the communication complexity is dominated by the total length of the {\em proofs} produced by the IT prover (i.e., $\pi$ to be linear queried), and the {\em answers} to the linear queries.
The compilers for distributed zero knowledge can be information-theoretic, and do not take advantage of the additional structure offered by polynomial IOPs or the low algebraic degree of the verifier's decision predicate.
Note that, unlike for fully linear IOPs, in a plain LIOP the dominant communication costs are unlikely to be the proof lengths of the IT prover (e.g., the proof length does not influence communication, since proofs could be ``compressed'' by hashing or homomorphic encryption). 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{CC for PIOP: Polynomial Commitments}
\label{sec:CC-LIOP:Poly-IOP}

The key to better cryptographic compilers is the following additional feature of the GKR-based LIOP: Each of the proof vectors $\pi_i$ can be viewed as defining the coefficients of a {\em polynomial} in a small number of variables, where each linear query to $\pi_i$ evaluates the polynomial at a single point.
More concretely, the long proof vector in the GKR-based LIOP defines a multilinear polynomial in $\log m$ variables that encodes $(x,w)$. 

This can be captured by a more refined notion of LIOP in which a proof is interpreted as the coefficient vector of a polynomial of bounded degree, typically in a small (at most logarithmic) number of variables, and a query is interpreted as an evaluation point.
This refinement of LIOP, referred to as {\em polynomial IOP} (PIOP) \cite{2019:BFS:transparent-SNARKs-from-DARK-compilers}, is motivated by possibility of cryptographic compilers that take advantage of the extra structure. 
(Another name for a closely related model is ``Algebraic Holographic Proof'' \cite{2020:CHMMVW:Marlin}.)
Cryptographic compilers for PIOP rely on efficient realizations of {\em polynomial commitment}, a functional commitment scheme that allows the prover to commit to a polynomial in a way that supports an efficient proof of evaluation on a given point.
\loosen


The first systems that combined the GKR protocol with polynomial commitments were Hyrax \cite{2018:SP:Doubly-efficient-zkSNARKs-without-trusted-setup} and (zk)-vSQL \cite{2017:SP:vSQL}. 
Hyrax used a transparent implementation of polynomial commitment based on discrete logarithm at the cost of proof size $\approx d+\sqrt{m}$.
The vSQL system could eliminate the $\sqrt{m}$ additive term by using a variant of a widely used polynomial commitment scheme \cite{2010:KZG:const-size-coms-to-poly-and-apps} that relies on a pairing-friendly group and requires a trusted setup. 
The subsequent Libra system \cite{2019:XZZPS:crypto:libra} combined a similar polynomial commitment with an improved zero-knowledge variant of the GKR-based PIOP. 
Virgo \cite{2020:ZXZS:virgo} is a variant of Libra that uses an efficient transparent polynomial commitment based only on symmetric cryptography, combining an IOP based on the FRI protocol with a GKR-based LIOP with $m=O(\log s)$. 
A similar kind of polynomial commitment was proposed in RedShift \cite{2019:KPV:redshift}. 
Another proposal \cite{2019:BFS:transparent-SNARKs-from-DARK-compilers} achieves a transparent polynomial commitment scheme with much better succinctness, using groups of an unknown order, though coming at the cost of high concrete prover complexity and not being post-quantum secure. 
A subsequent proposal \cite{DBLP:journals/iacr/Lee20b} gave a related polynomial commitment scheme that avoids the use of class groups (it is based on the symmetric external Diffie Hellman assumption) and mitigates the high prover costs. 
Additional works combining PIOPs with polynomial commitments to obtain succinct arguments include the following:
Kopis and Xiphos \cite{DBLP:journals/iacr/SettyL20} combines the PIOP for R1CS implicit in Spartan \cite{setty2020spartan} with the polynomial commitment Dory \cite{DBLP:journals/iacr/Lee20b} and variants;
Cerebrus \cite{2021:LSTW:eprint:linear-time-ZK-SNARKs-for-R1CS} distills a polynomial commitment scheme from an IOP given in Ligero \cite{2017:CCS:Ligero} and combines it with the same PIOP from Spartan \cite{setty2020spartan}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{CC for ILC}
\label{sec:CC-ILC}
Using a collision-resistant hash function, an ILC proof system can be compiled into a public-coin argument in the plain model with communication complexity roughly $\sum_i (n_i+m_i)$ \cite{2017:BCGGHJ:linear-time-ZKPs-arithm-circ-sat}.
